# Randomized Optimization
    Narasimha Lakamsani - nlakamsani3@gatech.edu
This project has 2 phases. The first phase evaluates 4 different randomized optimization algorithms: Random Hill Climbing (RHC), Simulated Annealing (SA), Genetic Algorithms (GA) and Mutual Information Maximizing Input Clustering (MIMIC). They are analyzed on 3 different optimization problems. The second phase involves comparing the randomized optimization algorithms against backpropagation in a neural network classifier.

### Dataset
* Hotel Reservations Dataset: https://www.kaggle.com/datasets/ahsan81/hotel-reservations-classification-dataset?select=Hotel+Reservations.csv

### Run Code Instuctions
* open collab notebook for part 1 with generic optimization problems:  https://colab.research.google.com/github/naralakamsani/randomized_optimization/blob/main/randomized_optimization_problems.ipynb
* open collab notebook for part 2 with neural network training:  https://colab.research.google.com/github/naralakamsani/randomized_optimization/blob/main/randomized_optimization_neural_net.ipynb
* Click on the runtime option above. Then proceed to click run all to run the entire notebooks
* note: It might take a while to finish running the whole notebooks, so it might be ideal to run only a few desired focused cells

**All code related files for this project can be found in the following repo:** https://github.com/naralakamsani/randomized_optimization.git
